"""
ì§ì ‘ì˜ìƒì œì‘ í´ë”ì˜ ë™ì˜ìƒì„ MediaPipeë¡œ ì²˜ë¦¬í•˜ì—¬ í‚¤í¬ì¸íŠ¸ JSON íŒŒì¼ë¡œ ë³€í™˜
model.ipynbì˜ ë°ì´í„° ë¡œë”© ë°©ì‹ê³¼ ë™ì¼í•œ êµ¬ì¡°ë¡œ ì €ì¥
"""
import cv2
import mediapipe as mp
import numpy as np
import json
import os
import glob
from pathlib import Path


#conda activate py311_env
#


# MediaPipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
mp_face_mesh = mp.solutions.face_mesh


if __name__ == "__main__":
    # ê²½ë¡œ ì„¤ì •
    video_folder = "/Users/garyeong/project-1/ì§ì ‘ì˜ìƒì œì‘_ë‹¨ì–´" # ë™ì˜ìƒ ë‹¨ì–´ ê²½ë¡œ 
    output_base_folder = "/Users/garyeong/project-1/dataset/ìì²´ì œì‘_ë‹¨ì–´_keypoints" 

    # í´ë” ì¡´ì¬ í™•ì¸
    if not os.path.exists(video_folder):
        print(f" ì…ë ¥ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_folder}")
        exit(1)

    # ì „ì²´ ë™ì˜ìƒ ì²˜ë¦¬
    process_all_videos(video_folder, output_base_folder)

    print(f"\n\në‹¤ìŒ ë‹¨ê³„:")
    print(f"1. ìƒì„±ëœ JSON íŒŒì¼ í™•ì¸: {output_base_folder}")
    print(f"2. model.ipynbì—ì„œ label_base_dir, keypoint_base_dir ê²½ë¡œ ìˆ˜ì •")
    print(f"3. model.ipynb ì‹¤í–‰í•˜ì—¬ í•™ìŠµ ë°ì´í„° ìƒì„±")



def extract_keypoints_from_frame(frame, pose, hands, face_mesh):
    """
    ë‹¨ì¼ í”„ë ˆì„ì—ì„œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (model.ipynbì˜ 411ì°¨ì› í˜•ì‹)

    Returns:
        dict: OpenPose í˜•ì‹ì˜ í‚¤í¬ì¸íŠ¸ ë°ì´í„°
              {
                  "people": [{
                      "pose_keypoints_2d": [75ê°œ],    # 25 landmarks * 3 (x, y, confidence)
                      "face_keypoints_2d": [210ê°œ],   # 70 landmarks * 3
                      "hand_left_keypoints_2d": [63ê°œ],   # 21 landmarks * 3
                      "hand_right_keypoints_2d": [63ê°œ]   # 21 landmarks * 3
                  }]
              }
    """
    # BGR â†’ RGB ë³€í™˜
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # MediaPipe ì²˜ë¦¬
    pose_results = pose.process(rgb_frame)
    hands_results = hands.process(rgb_frame)
    face_results = face_mesh.process(rgb_frame)

    # 1. Pose keypoints (25 landmarks * 3 = 75)
    pose_kps = []
    if pose_results.pose_landmarks:
        for i in range(25):  # ì²˜ìŒ 25ê°œ ëœë“œë§ˆí¬ë§Œ ì‚¬ìš©
            if i < len(pose_results.pose_landmarks.landmark):
                lm = pose_results.pose_landmarks.landmark[i]
                pose_kps.extend([lm.x, lm.y, lm.visibility])
            else:
                pose_kps.extend([0.0, 0.0, 0.0])
    else:
        pose_kps = [0.0] * 75

    # 2. Face keypoints (70 landmarks * 3 = 210)
    face_kps = []
    if face_results.multi_face_landmarks:
        face_landmarks = face_results.multi_face_landmarks[0]
        for i in range(70):  # ì²˜ìŒ 70ê°œ ëœë“œë§ˆí¬ë§Œ ì‚¬ìš©
            if i < len(face_landmarks.landmark):
                lm = face_landmarks.landmark[i]
                face_kps.extend([lm.x, lm.y, lm.z])
            else:
                face_kps.extend([0.0, 0.0, 0.0])
    else:
        face_kps = [0.0] * 210

    # 3. Hand keypoints (21 * 3 * 2 = 126)
    left_hand_kps = [0.0] * 63
    right_hand_kps = [0.0] * 63

    if hands_results.multi_hand_landmarks:
        for idx, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):
            handedness = hands_results.multi_handedness[idx].classification[0].label
            hand_kps = []
            for lm in hand_landmarks.landmark:
                hand_kps.extend([lm.x, lm.y, lm.z])

            if handedness == "Left":
                left_hand_kps = hand_kps
            elif handedness == "Right":
                right_hand_kps = hand_kps

    # OpenPose í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ (ì´ 75 + 210 + 63 + 63 = 411)
    keypoint_data = {
        "people": [{
            "pose_keypoints_2d": pose_kps,
            "face_keypoints_2d": face_kps,
            "hand_left_keypoints_2d": left_hand_kps,
            "hand_right_keypoints_2d": right_hand_kps
        }]
    }

    return keypoint_data


def process_video_to_json(video_path, output_folder, label_name):
    """
    ë™ì˜ìƒì„ í”„ë ˆì„ë³„ë¡œ ì²˜ë¦¬í•˜ì—¬ JSON í‚¤í¬ì¸íŠ¸ íŒŒì¼ë“¤ë¡œ ì €ì¥

    Args:
        video_path: ì…ë ¥ ë™ì˜ìƒ ê²½ë¡œ
        output_folder: ì¶œë ¥ í´ë” ê²½ë¡œ
        label_name: ë¼ë²¨ ì´ë¦„ (ì˜ˆ: 'ã„±', 'ã„´', ...)
    """
    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(output_folder, exist_ok=True)

    # ë™ì˜ìƒ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"ë™ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return False

    # ë™ì˜ìƒ ì •ë³´
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    print(f"\nğŸ“¹ ì²˜ë¦¬ ì¤‘: {label_name}")
    print(f"   ê²½ë¡œ: {video_path}")
    print(f"   FPS: {fps}, ì´ í”„ë ˆì„: {total_frames}")

    # MediaPipe ì´ˆê¸°í™”
    with mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,
        enable_segmentation=False,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as pose, mp_hands.Hands(
        static_image_mode=False,
        max_num_hands=2,
        model_complexity=1,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as hands, mp_face_mesh.FaceMesh(
        static_image_mode=False,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as face_mesh:

        frame_idx = 0
        processed_frames = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
            keypoint_data = extract_keypoints_from_frame(frame, pose, hands, face_mesh)

            # JSON íŒŒì¼ë¡œ ì €ì¥ (OpenPose í˜•ì‹: {video_id}_{frame_number}_keypoints.json)
            json_filename = f"{label_name}_{frame_idx:06d}_keypoints.json"
            json_path = os.path.join(output_folder, json_filename)

            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(keypoint_data, f, ensure_ascii=False, indent=2)

            frame_idx += 1
            processed_frames += 1

            # ì§„í–‰ ìƒí™© í‘œì‹œ
            if frame_idx % 10 == 0:
                progress = (frame_idx / total_frames) * 100 if total_frames > 0 else 0
                print(f"   ì§„í–‰: {frame_idx}/{total_frames} ({progress:.1f}%)", end='\r')

        cap.release()
        print(f"\n ì™„ë£Œ: {processed_frames}ê°œ í”„ë ˆì„ ì²˜ë¦¬ë¨")
        return True


def create_morpheme_label_file(output_folder, label_name):
    """
    model.ipynbì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜•ì‹ì˜ ë¼ë²¨ JSON íŒŒì¼ ìƒì„±

    í˜•ì‹:
    {
        "data": [{
            "attributes": [{
                "name": "ã„±"
            }]
        }]
    }
    """
    label_data = {
        "data": [{
            "attributes": [{
                "name": label_name
            }]
        }]
    }

    # ë¼ë²¨ íŒŒì¼ ì €ì¥
    label_filename = f"{label_name}_morpheme.json"
    label_path = os.path.join(output_folder, label_filename)

    with open(label_path, 'w', encoding='utf-8') as f:
        json.dump(label_data, f, ensure_ascii=False, indent=2)

    print(f" ë¼ë²¨ íŒŒì¼ ìƒì„±: {label_filename}")


def process_all_videos(video_folder, output_base_folder):
    """
    ì§ì ‘ì˜ìƒì œì‘ í´ë”ì˜ ëª¨ë“  ë™ì˜ìƒì„ ì²˜ë¦¬

    Args:
        video_folder: ì…ë ¥ ë™ì˜ìƒ í´ë” (ì§ì ‘ì˜ìƒì œì‘)
        output_base_folder: ì¶œë ¥ ê¸°ë³¸ í´ë”
    """
    # ë™ì˜ìƒ íŒŒì¼ ì°¾ê¸°
    video_files = glob.glob(os.path.join(video_folder, "*.mov"))
    video_files.extend(glob.glob(os.path.join(video_folder, "*.mp4")))
    video_files = sorted(video_files)

    if not video_files:
        print(" ë™ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return

    print(f"\n{'='*70}")
    print(f"ì§ì ‘ì˜ìƒì œì‘ í´ë” ë™ì˜ìƒ â†’ JSON í‚¤í¬ì¸íŠ¸ ë³€í™˜")
    print(f"{'='*70}")
    print(f"ì…ë ¥ í´ë”: {video_folder}")
    print(f"ì¶œë ¥ í´ë”: {output_base_folder}")
    print(f"ì´ ë™ì˜ìƒ: {len(video_files)}ê°œ")
    print(f"{'='*70}\n")

    # ê° ë™ì˜ìƒ ì²˜ë¦¬
    success_count = 0
    fail_count = 0

    for idx, video_path in enumerate(video_files, 1):
        # íŒŒì¼ëª…ì—ì„œ ë¼ë²¨ ì¶”ì¶œ (ì˜ˆ: 'ã„±.mov' â†’ 'ã„±')
        filename = os.path.basename(video_path)
        label_name = os.path.splitext(filename)[0]

        # ì¶œë ¥ í´ë”: output_base_folder/label_name/
        output_folder = os.path.join(output_base_folder, label_name)

        print(f"\n[{idx}/{len(video_files)}] {label_name}")

        # ë™ì˜ìƒ ì²˜ë¦¬
        success = process_video_to_json(video_path, output_folder, label_name)

        if success:
            # ë¼ë²¨ íŒŒì¼ ìƒì„±
            create_morpheme_label_file(output_folder, label_name)
            success_count += 1
        else:
            fail_count += 1

    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*70}")
    print(f"ë³€í™˜ ì™„ë£Œ!")
    print(f"{'='*70}")
    print(f" ì„±ê³µ: {success_count}ê°œ")
    print(f" ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"\nì¶œë ¥ êµ¬ì¡°:")
    print(f"  {output_base_folder}/")
    print(f"  â”œâ”€â”€ ã„±/")
    print(f"  â”‚   â”œâ”€â”€ ã„±_000000_keypoints.json")
    print(f"  â”‚   â”œâ”€â”€ ã„±_000001_keypoints.json")
    print(f"  â”‚   â”œâ”€â”€ ...")
    print(f"  â”‚   â””â”€â”€ ã„±_morpheme.json")
    print(f"  â”œâ”€â”€ ã„´/")
    print(f"  â”‚   â””â”€â”€ ...")
    print(f"  â””â”€â”€ ...")
    print(f"\n ì´ì œ model.ipynbì—ì„œ ì´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    print(f"{'='*70}")


