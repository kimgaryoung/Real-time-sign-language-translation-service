"""
ì§ì ‘ì˜ìƒì œì‘ í´ë”ì˜ ë™ì˜ìƒì„ MediaPipeë¡œ ì²˜ë¦¬í•˜ì—¬ í‚¤í¬ì¸íŠ¸ JSON íŒŒì¼ë¡œ ë³€í™˜
model.ipynbì˜ ë°ì´í„° ë¡œë”© ë°©ì‹ê³¼ ë™ì¼í•œ êµ¬ì¡°ë¡œ ì €ì¥
"""
import cv2
import mediapipe as mp
import numpy as np
import json
import os
import glob
import sys  # exit ì‚¬ìš©ì„ ìœ„í•´ ì¶”ê°€

# MediaPipe ì´ˆê¸°í™” (ì „ì—­ ë³€ìˆ˜ ìœ ì§€)
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
mp_face_mesh = mp.solutions.face_mesh

def extract_keypoints_from_frame(frame, pose, hands, face_mesh):
    """
    ë‹¨ì¼ í”„ë ˆì„ì—ì„œ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (model.ipynbì˜ 411ì°¨ì› í˜•ì‹)
    """
    # BGR â†’ RGB ë³€í™˜
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # MediaPipe ì²˜ë¦¬
    pose_results = pose.process(rgb_frame)
    hands_results = hands.process(rgb_frame)
    face_results = face_mesh.process(rgb_frame)

    # 1. Pose keypoints (25 landmarks * 3 = 75)
    pose_kps = []
    if pose_results.pose_landmarks:
        for i in range(25):  # ì²˜ìŒ 25ê°œ ëœë“œë§ˆí¬ë§Œ ì‚¬ìš©
            if i < len(pose_results.pose_landmarks.landmark):
                lm = pose_results.pose_landmarks.landmark[i]
                pose_kps.extend([lm.x, lm.y, lm.visibility])
            else:
                pose_kps.extend([0.0, 0.0, 0.0])
    else:
        pose_kps = [0.0] * 75

    # 2. Face keypoints (70 landmarks * 3 = 210)
    face_kps = []
    if face_results.multi_face_landmarks:
        face_landmarks = face_results.multi_face_landmarks[0]
        for i in range(70):  # ì²˜ìŒ 70ê°œ ëœë“œë§ˆí¬ë§Œ ì‚¬ìš©
            if i < len(face_landmarks.landmark):
                lm = face_landmarks.landmark[i]
                face_kps.extend([lm.x, lm.y, lm.z])
            else:
                face_kps.extend([0.0, 0.0, 0.0])
    else:
        face_kps = [0.0] * 210

    # 3. Hand keypoints (21 * 3 * 2 = 126)
    left_hand_kps = [0.0] * 63
    right_hand_kps = [0.0] * 63

    if hands_results.multi_hand_landmarks:
        for idx, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):
            # handedness ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
            if hands_results.multi_handedness:
                handedness = hands_results.multi_handedness[idx].classification[0].label
            else:
                handedness = "Unknown"
            
            hand_kps = []
            for lm in hand_landmarks.landmark:
                hand_kps.extend([lm.x, lm.y, lm.z])

            if handedness == "Left":
                left_hand_kps = hand_kps
            elif handedness == "Right":
                right_hand_kps = hand_kps

    # OpenPose í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ (ì´ 75 + 210 + 63 + 63 = 411)
    keypoint_data = {
        "people": [{
            "pose_keypoints_2d": pose_kps,
            "face_keypoints_2d": face_kps,
            "hand_left_keypoints_2d": left_hand_kps,
            "hand_right_keypoints_2d": right_hand_kps
        }]
    }

    return keypoint_data

def process_video_to_json(video_path, output_folder, label_name):
    """
    ë™ì˜ìƒì„ í”„ë ˆì„ë³„ë¡œ ì²˜ë¦¬í•˜ì—¬ JSON í‚¤í¬ì¸íŠ¸ íŒŒì¼ë“¤ë¡œ ì €ì¥
    """
    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(output_folder, exist_ok=True)

    # ë™ì˜ìƒ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"ë™ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return False

    # ë™ì˜ìƒ ì •ë³´
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    print(f"\nğŸ“¹ ì²˜ë¦¬ ì¤‘: {label_name}")
    print(f"   ê²½ë¡œ: {video_path}")
    
    # MediaPipe ì´ˆê¸°í™” (with êµ¬ë¬¸ ì‚¬ìš©)
    with mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,
        enable_segmentation=False,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as pose, mp_hands.Hands(
        static_image_mode=False,
        max_num_hands=2,
        model_complexity=1,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as hands, mp_face_mesh.FaceMesh(
        static_image_mode=False,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    ) as face_mesh:

        frame_idx = 0
        processed_frames = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
            keypoint_data = extract_keypoints_from_frame(frame, pose, hands, face_mesh)

            # JSON íŒŒì¼ë¡œ ì €ì¥
            json_filename = f"{label_name}_{frame_idx:06d}_keypoints.json"
            json_path = os.path.join(output_folder, json_filename)

            # ë“¤ì—¬ì“°ê¸°(indent)ë¥¼ Noneìœ¼ë¡œ í•˜ì—¬ ìš©ëŸ‰ ì¤„ì„ (ì˜µì…˜)
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(keypoint_data, f, ensure_ascii=False)

            frame_idx += 1
            processed_frames += 1

            # ì§„í–‰ ìƒí™© í‘œì‹œ
            if frame_idx % 10 == 0:
                progress = (frame_idx / total_frames) * 100 if total_frames > 0 else 0
                print(f"   ì§„í–‰: {frame_idx}/{total_frames} ({progress:.1f}%)", end='\r')

        cap.release()
        print(f"\n   ì™„ë£Œ: {processed_frames}ê°œ í”„ë ˆì„ ì²˜ë¦¬ë¨")
        return True

def create_morpheme_label_file(output_folder, label_name):
    """
    model.ipynbì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜•ì‹ì˜ ë¼ë²¨ JSON íŒŒì¼ ìƒì„±
    """
    label_data = {
        "data": [{
            "attributes": [{
                "name": label_name
            }]
        }]
    }

    # ë¼ë²¨ íŒŒì¼ ì €ì¥
    label_filename = f"{label_name}_morpheme.json"
    label_path = os.path.join(output_folder, label_filename)

    with open(label_path, 'w', encoding='utf-8') as f:
        json.dump(label_data, f, ensure_ascii=False, indent=2)

    # print(f" ë¼ë²¨ íŒŒì¼ ìƒì„±: {label_filename}")

def process_all_videos(video_folder, output_base_folder):
    """
    í´ë”ì˜ ëª¨ë“  ë™ì˜ìƒì„ ì²˜ë¦¬ (íŒŒì¼ëª…ì— ë”°ë¼ ë¼ë²¨ ê·¸ë£¹í™”)
    """
    # ë™ì˜ìƒ íŒŒì¼ ì°¾ê¸° (mp4, mov ëŒ€ì†Œë¬¸ì ë¬´ê´€)
    video_files = []
    for ext in ["*.mov", "*.MOV", "*.mp4", "*.MP4"]:
        video_files.extend(glob.glob(os.path.join(video_folder, ext)))
    
    video_files = sorted(video_files)

    if not video_files:
        print("âŒ ë™ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return

    print(f"\n{'='*70}")
    print(f"ë™ì˜ìƒ â†’ JSON í‚¤í¬ì¸íŠ¸ ë³€í™˜ ì‹œì‘")
    print(f"ì…ë ¥: {video_folder}")
    print(f"ì¶œë ¥: {output_base_folder}")
    print(f"ì´ íŒŒì¼: {len(video_files)}ê°œ")
    print(f"{'='*70}")

    success_count = 0
    fail_count = 0

    for idx, video_path in enumerate(video_files, 1):
        filename = os.path.basename(video_path)
        
        # [ì¤‘ìš”] íŒŒì¼ëª…ì—ì„œ ë¼ë²¨ ì¶”ì¶œ ë¡œì§ ìˆ˜ì •
        # ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”_1.mp4" -> "ì•ˆë…•í•˜ì„¸ìš”"
        raw_name = os.path.splitext(filename)[0]
        if '_' in raw_name:
            label_name = raw_name.split('_')[0]
        else:
            label_name = raw_name

        # ì¶œë ¥ í´ë”: output_base_folder/label_name/
        output_folder = os.path.join(output_base_folder, label_name)

        print(f"\n[{idx}/{len(video_files)}] íŒŒì¼: {filename} â†’ ë¼ë²¨: {label_name}")

        # ë™ì˜ìƒ ì²˜ë¦¬
        success = process_video_to_json(video_path, output_folder, label_name)

        if success:
            # ë¼ë²¨ íŒŒì¼ ìƒì„± (ì´ë¯¸ ì¡´ì¬í•´ë„ ë®ì–´ì“°ê¸° ë˜ë¯€ë¡œ ì•ˆì „)
            create_morpheme_label_file(output_folder, label_name)
            success_count += 1
        else:
            fail_count += 1

    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*70}")
    print(f"ë³€í™˜ ì™„ë£Œ!")
    print(f"{'='*70}")
    print(f" ì„±ê³µ: {success_count}ê°œ")
    print(f" ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"\nì¶œë ¥ ê²½ë¡œ: {output_base_folder}")
    print(f"ì´ì œ model.ipynbì—ì„œ ì´ ë°ì´í„°ë¥¼ í•™ìŠµì— ì‚¬ìš©í•˜ì„¸ìš”.")
    print(f"{'='*70}")

# ==========================================
# ì‹¤í–‰ë¶€ (Main) 
# ==========================================
if __name__ == "__main__":
    # ê²½ë¡œ ì„¤ì • (ìœˆë„ìš° ê²½ë¡œ raw string ì ìš©)
    # 1. ì…ë ¥: ì´¬ì˜í•œ ë™ì˜ìƒì´ ìˆëŠ” í´ë”
    video_folder = r"C:/Users/yues7/OneDrive/ì‚¬ì§„/Camera Roll"
    
    # 2. ì¶œë ¥: ê²°ê³¼ê°€ ì €ì¥ë  ê²½ë¡œ
    output_base_folder = r"C:/j/datasetìì²´ì œì‘_ë‹¨ì–´_keypoints" 

    # í´ë” ì¡´ì¬ í™•ì¸
    if not os.path.exists(video_folder):
        print(f"âŒ ì…ë ¥ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_folder}")
        print("ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    # ì „ì²´ ë™ì˜ìƒ ì²˜ë¦¬ ì‹œì‘
    process_all_videos(video_folder, output_base_folder)